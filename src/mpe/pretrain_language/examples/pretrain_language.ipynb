{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from random import randint\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_goal_id = 3         # dimension of goal id (color of other agent landmark)\n",
    "n_tokens = 10         # number of language tokes\n",
    "n_landmarks = 3       # number of landmarks\n",
    "batch_size = 128      # batch size\n",
    "n_episodes = 20000    # number of training episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2token(num: int) -> chr:\n",
    "  return chr(ord('A')+num)\n",
    "\n",
    "\n",
    "class MLPNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=64, non_linear=nn.ReLU()):\n",
    "        super(MLPNetwork, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            non_linear,\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            non_linear,\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        ).apply(self.init)\n",
    "\n",
    "    @staticmethod\n",
    "    def init(m):\n",
    "        \"\"\"init parameter of the module\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark colors\n",
    "landmarks_c = [[0.75, 0.25, 0.25], [0.25, 0.75, 0.25], [0.25, 0.25, 0.75]]\n",
    "landmarks_c = [torch.tensor(l).unsqueeze(0) for l in landmarks_c]\n",
    "\n",
    "# init agents\n",
    "speaker = MLPNetwork(3, n_tokens)\n",
    "listener = MLPNetwork(2 + 2*n_landmarks + n_goal_id + n_tokens, 2)\n",
    "params = list(speaker.parameters()) + list(listener.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "for i in range(n_episodes):\n",
    "  # relative position of landmarks wrt to listener\n",
    "  landmarks_p = (torch.rand((batch_size, 2*n_landmarks)) - 0.5) * 2\n",
    "  # velocity of listener\n",
    "  vel = torch.rand((batch_size, 2))\n",
    "  # sample target landmark\n",
    "  ix = randint(0, n_landmarks-1)\n",
    "  # pass through observer\n",
    "  msg = F.gumbel_softmax(speaker(landmarks_c[ix].repeat(batch_size, 1)), hard=True)\n",
    "  # goal id (kinda useless to have it)\n",
    "  goal_id = torch.cat(list(landmarks_c[randint(0, n_landmarks-1)] for _ in range(batch_size)), 0)\n",
    "  # listener obesrvation\n",
    "  obs = torch.cat((vel, landmarks_p, goal_id, msg), 1)\n",
    "  # predict landmark pos\n",
    "  pred = listener(obs)\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  target = landmarks_p[:,ix*2:(ix+1)*2]\n",
    "  lossfun = nn.L1Loss()\n",
    "  loss = lossfun(pred, target)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if i%100==0:\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative position of landmarks wrt to listener\n",
    "landmarks_p = [(torch.rand((1, 2)) - 0.5) * 2 for _ in range(n_landmarks)]\n",
    "# velocity of listener\n",
    "vel = torch.rand((1, 2))\n",
    "# sample target landmark\n",
    "ix = randint(0, n_landmarks-1)\n",
    "# pass through observer\n",
    "msg = F.gumbel_softmax(speaker(landmarks_c[ix]), hard=True)\n",
    "print(f\"Observer output: {msg}\")\n",
    "print(f\"msg: {num2token(msg.unsqueeze(0).argmax().item())}\")\n",
    "# goal id (kinda useless to have it)\n",
    "goal_id = landmarks_c[randint(0, n_landmarks-1)]\n",
    "# listener obesrvation\n",
    "obs = torch.cat((vel, *landmarks_p, goal_id, msg), 1)\n",
    "# predict landmark pos\n",
    "pred = listener(obs)\n",
    "print(ix)\n",
    "print(landmarks_p[ix])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder to save result\n",
    "env_dir = os.path.join(os.path.abspath('../'), 'results/', 'simple_reference_v2')\n",
    "if not os.path.exists(env_dir):\n",
    "  os.makedirs(env_dir)\n",
    "total_files = len([file for file in os.listdir(env_dir)])\n",
    "result_dir = os.path.join(env_dir, f'{total_files + 1}')\n",
    "os.makedirs(result_dir)\n",
    "\n",
    "# dict with models\n",
    "models = {'speaker': speaker, 'listener': listener}\n",
    "\n",
    "# store models\n",
    "torch.save(\n",
    "    {name: model.state_dict() for name, model in models.items()},  # actor parameter\n",
    "    os.path.join(result_dir, 'model.pt')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "env_dir = os.path.join(os.path.abspath('../'), 'results/', 'simple_reference_v2')\n",
    "if not os.path.exists(env_dir):\n",
    "  os.makedirs(env_dir)\n",
    "total_files = len([file for file in os.listdir(env_dir)])\n",
    "result_dir = os.path.join(env_dir, f'{total_files + 1}')\n",
    "os.makedirs(result_dir)\n",
    "\n",
    "# store args\n",
    "config = {\"num_agents\": 2, \"num_landmarks\": 3}\n",
    "\n",
    "with open(os.path.join(result_dir, 'config.json'), 'w+') as f:\n",
    "    json.dump(config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
